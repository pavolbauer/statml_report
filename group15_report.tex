\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2016
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2016}

\usepackage{nips_2016}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2016}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx,color}

\newcommand{\todo}[1]{\textcolor{blue}{#1}}

\title{Group S15: Mini Project Report}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Petar Bokan \\
  \texttt{petar.bokan@physics.uu.se} \\
  %% examples of more authors
   \And
  Pavol Bauer \\
  \texttt{pavol.bauer@it.uu.se} \\
}

%add lines according to instructions
\makeatletter
\renewcommand{\@noticestring}{}
\makeatother

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
Supervised machine learning methods such as regression, random forest and boosting gained enormous importance in research as well as industrial applications.
We consider a problem classifying favourite songs based on a feature dataset obtained from a streaming music company.
We train and validate the random forest and boosting classifiers and test their performance on a unknown test set.

\end{abstract}

\section{Introduction}

In this miniproject we are going to consider a classification problem in statistical machine learning.
The goal is to use different 

\section{Used methods}

\subsection{Random Forest}

\subsection{Boosting}

\section{Implementation and Validation}

\subsection{Random Forest}

\subsection{Boosting}

\section{Evaluation}

\subsection{Random Forest}

\subsection{Boosting}

\subsection{Naive Classifier}

\section{Conclusion}

\section{Contributions}

So far anonymized.

\section*{References}

\small

[1] Alexander, J.A.\ \& Mozer, M.C.\ (1995) Template-based algorithms
for connectionist rule extraction. In G.\ Tesauro, D.S.\ Touretzky and
T.K.\ Leen (eds.), {\it Advances in Neural Information Processing
  Systems 7}, pp.\ 609--616. Cambridge, MA: MIT Press.

[2] Bower, J.M.\ \& Beeman, D.\ (1995) {\it The Book of GENESIS:
  Exploring Realistic Neural Models with the GEneral NEural SImulation
  System.}  New York: TELOS/Springer--Verlag.

[3] Hasselmo, M.E., Schnell, E.\ \& Barkai, E.\ (1995) Dynamics of
learning and recall at excitatory recurrent synapses and cholinergic
modulation in rat hippocampal region CA3. {\it Journal of
  Neuroscience} {\bf 15}(7):5249-5262.

\end{document}
